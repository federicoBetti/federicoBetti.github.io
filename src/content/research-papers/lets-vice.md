---
title: "Let's ViCE! Mimicking Human Cognitive Behavior in Image Generation Evaluation"
authors: "F Betti, J Staiano, L Baraldi, L Baraldi, R Cucchiara, N Sebe"
conference: "Proceedings of the 31st ACM International Conference on Multimedia, 9306-9312"
pubDate: "Oct 29 2023"
description: "We introduce ViCE, a novel automated method for evaluating consistency between generated images and text prompts by combining Large Language Models with Visual Question Answering in a process inspired by human cognitive assessment."
link: "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Ms5ctkUAAAAJ&citation_for_view=Ms5ctkUAAAAJ:W7OEmFMy1HYC"
tags: ["Computer Vision", "Image Generation", "Cognitive Science", "Evaluation Metrics", "Visual Question Answering", "LLMs", "Vision-Language Models"]
pdfUrl: "https://dl.acm.org/doi/pdf/10.1145/3581783.3612706"
---

## Abstract

We introduce ViCE (Visual Concept Evaluation), a novel automated method to assess consistency between generated/edited images and their corresponding prompts/instructions, inspired by human cognitive processes. Despite advances in image generation quality, no methodical frameworks exist to quantitatively measure content quality and prompt adherence. ViCE combines Large Language Models (LLMs) and Visual Question Answering (VQA) in a unified pipeline that outlines visual concepts, formulates verification questions, investigates the image through Q&A, and scores the results, offering a promising approach to automatic evaluation for increasingly sophisticated generation tasks.

## Key Contributions

1. Novel evaluation framework based on human cognitive processes for image generation assessment
2. Combination of LLMs and VQA in a unified evaluation pipeline
3. Systematic approach to quantify consistency between generated images and text prompts
4. Preliminary validation showing promising results for automatic image quality evaluation 